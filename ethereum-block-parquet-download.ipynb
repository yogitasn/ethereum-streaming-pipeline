{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94209dfe-33fe-46d4-a650-e76603632480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**## Batch processing of Ethereum data from AWS S3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2481978a-ceee-44f6-b42e-7c510a163d27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD27 Using Catalog: blockchain, Schema: ethereum\n\uD83D\uDCE6 Downloading 20 files from s3://aws-public-blockchain/v1.0/eth/blocks/\n[1/5] CREATE CATALOG IF NOT EXISTS blockchain\n  ✅ Success\n[2/5] CREATE SCHEMA IF NOT EXISTS blockchain.ethereum\n  ✅ Success\n[3/5] CREATE VOLUME IF NOT EXISTS blockchain.ethereum.ethereum\n  ✅ Success\n[4/5] CREATE VOLUME IF NOT EXISTS blockchain.ethereum.ethereum_checkpoints\n  ✅ Success\n[5/5] CREATE VOLUME IF NOT EXISTS blockchain.ethereum.ethereum_schemas\n  ✅ Success\n\nCreated/verified UC objects. Paths available:\n  Data: /Volumes/blockchain/ethereum/ethereum\n  Checkpoints: /Volumes/blockchain/ethereum/ethereum_checkpoints\n  Schemas: /Volumes/blockchain/ethereum/ethereum_schemas\n\n\uD83D\uDCE5 Downloading to: /Volumes/blockchain/ethereum/ethereum\n[1/20] part-00000-32767f69-9150-49ac-9c03-45f34b103c34-c000.snappy.parquet ... ✓\n[2/20] part-00000-62c9c86c-8a10-4196-b54c-01a2a139f4ec-c000.snappy.parquet ... ✓\n[3/20] part-00000-5438c668-b9c9-4b0a-8a35-64ff30b73cdf-c000.snappy.parquet ... ✓\n[4/20] part-00000-e0818341-7c32-4d1d-8fa5-a6fb563777ea-c000.snappy.parquet ... ✓\n[5/20] part-00000-70e7bc53-8610-4048-b386-93edcd06465c-c000.snappy.parquet ... ✓\n[6/20] part-00000-d101c8a0-5c86-4553-9acb-b62f581fcaea-c000.snappy.parquet ... ✓\n[7/20] part-00000-6f9c0e66-8518-4611-aa66-b74c74204f8e-c000.snappy.parquet ... ✓\n[8/20] part-00000-2630a26b-4e5f-4ef6-9dcd-9697cc9848d2-c000.snappy.parquet ... ✓\n[9/20] part-00000-6e063101-19d0-4453-8227-f4abea6e3ed8-c000.snappy.parquet ... ✓\n[10/20] part-00000-a28cb51d-dbf1-47eb-8f10-46c6f6c0bd5f-c000.snappy.parquet ... ✓\n[11/20] part-00000-3dc36afe-e794-4f74-8156-9179c7f508a7-c000.snappy.parquet ... ✓\n[12/20] part-00000-18762fa7-e18c-4b0b-b999-43fb33683869-c000.snappy.parquet ... ✓\n[13/20] part-00000-7d418bc8-e2a3-4e13-8732-7d28f82a0005-c000.snappy.parquet ... ✓\n[14/20] part-00000-f1e5ba7c-d97b-4fcd-8d16-cf69ef4588dd-c000.snappy.parquet ... ✓\n[15/20] part-00000-2bf9a037-54bc-4fa9-995b-4faece48f5de-c000.snappy.parquet ... ✓\n[16/20] part-00000-48994bb1-434f-4576-9eb6-e9a415fc3a42-c000.snappy.parquet ... ✓\n[17/20] part-00000-2a235a11-0ea4-45cc-98ea-096d37747e83-c000.snappy.parquet ... ✓\n[18/20] part-00000-6327ace7-c2fc-4dcc-9f2e-18b5dddbf8d4-c000.snappy.parquet ... ✓\n[19/20] part-00000-b92723ff-fb43-40d3-971d-e33fe2405596-c000.snappy.parquet ... ✓\n[20/20] part-00000-ca2823d3-0c32-4141-bdd3-7bc6fad4706c-c000.snappy.parquet ... ✓\n✅ Download complete!\n"
     ]
    }
   ],
   "source": [
    "# Databricks notebook source\n",
    "# === SIMPLE PARAMETERIZATION (ONLY NECESSARY VARIABLES) ===\n",
    "# Parameterize only what needs to be variable for reusability\n",
    "dbutils.widgets.text(\"catalog_name\", \"blockchain\", \"Catalog Name\")\n",
    "dbutils.widgets.text(\"schema_name\", \"ethereum\", \"Schema Name\")\n",
    "dbutils.widgets.text(\"num_files\", \"20\", \"Number of Files to Download\")\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# Get widget values\n",
    "CATALOG = dbutils.widgets.get(\"catalog_name\")\n",
    "SCHEMA = dbutils.widgets.get(\"schema_name\")\n",
    "NUM_FILES = int(dbutils.widgets.get(\"num_files\"))\n",
    "\n",
    "# Hard-coded values (no need to parameterize constants)\n",
    "AWS_BUCKET = \"aws-public-blockchain\"\n",
    "S3_PREFIX = \"v1.0/eth/blocks/\"\n",
    "\n",
    "# Unity Catalog volume paths for data organization\n",
    "DATA_VOLUME = f\"/Volumes/{CATALOG}/{SCHEMA}/ethereum\"\n",
    "CHECKPOINT_VOLUME = f\"/Volumes/{CATALOG}/{SCHEMA}/ethereum_checkpoints\"\n",
    "SCHEMA_VOLUME = f\"/Volumes/{CATALOG}/{SCHEMA}/ethereum_schemas\"\n",
    "\n",
    "print(f\"\uD83D\uDD27 Using Catalog: {CATALOG}, Schema: {SCHEMA}\")\n",
    "print(f\"\uD83D\uDCE6 Downloading {NUM_FILES} files from s3://{AWS_BUCKET}/{S3_PREFIX}\")\n",
    "\n",
    "# === UNITY CATALOG SETUP ===\n",
    "stmts = [\n",
    "    f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\",\n",
    "    f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SCHEMA}\",\n",
    "    f\"CREATE VOLUME IF NOT EXISTS {CATALOG}.{SCHEMA}.ethereum\",\n",
    "    f\"CREATE VOLUME IF NOT EXISTS {CATALOG}.{SCHEMA}.ethereum_checkpoints\",\n",
    "    f\"CREATE VOLUME IF NOT EXISTS {CATALOG}.{SCHEMA}.ethereum_schemas\",\n",
    "]\n",
    "\n",
    "for i, s in enumerate(stmts, 1):\n",
    "    print(f\"[{i}/{len(stmts)}] {s}\")\n",
    "    try:\n",
    "        spark.sql(s)\n",
    "        print(\"  ✅ Success\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error: {e}\")\n",
    "\n",
    "print(f\"\\nCreated/verified UC objects. Paths available:\")\n",
    "print(f\"  Data: {DATA_VOLUME}\")\n",
    "print(f\"  Checkpoints: {CHECKPOINT_VOLUME}\")\n",
    "print(f\"  Schemas: {SCHEMA_VOLUME}\")\n",
    "\n",
    "# === DATA DOWNLOAD ===\n",
    "import os\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "print(f\"\\n\uD83D\uDCE5 Downloading to: {DATA_VOLUME}\")\n",
    "os.makedirs(DATA_VOLUME, exist_ok=True)\n",
    "\n",
    "# Configure anonymous S3 client (no AWS credentials needed!)\n",
    "s3 = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "# Collect parquet files from S3\n",
    "keys = []\n",
    "token = None\n",
    "\n",
    "while len(keys) < NUM_FILES:\n",
    "    params = {\n",
    "        \"Bucket\": AWS_BUCKET, \n",
    "        \"Prefix\": S3_PREFIX, \n",
    "        \"MaxKeys\": min(1000, NUM_FILES - len(keys))\n",
    "    }\n",
    "    if token:\n",
    "        params[\"ContinuationToken\"] = token\n",
    "    \n",
    "    resp = s3.list_objects_v2(**params)\n",
    "    \n",
    "    for obj in resp.get(\"Contents\", []) or []:\n",
    "        if obj[\"Key\"].endswith(\".parquet\"):\n",
    "            keys.append(obj[\"Key\"])\n",
    "            if len(keys) >= NUM_FILES:\n",
    "                break\n",
    "    \n",
    "    if not resp.get(\"IsTruncated\"):\n",
    "        break\n",
    "    token = resp.get(\"NextContinuationToken\")\n",
    "\n",
    "if not keys:\n",
    "    raise RuntimeError(f\"No parquet files found under s3://{AWS_BUCKET}/{S3_PREFIX}\")\n",
    "\n",
    "# Download files with progress tracking\n",
    "for i, key in enumerate(keys, 1):\n",
    "    rel_path = key.replace(\"v1.0/eth/\", \"\")\n",
    "    dest_path = os.path.join(DATA_VOLUME, rel_path)\n",
    "    os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "    \n",
    "    print(f\"[{i}/{len(keys)}] {os.path.basename(key)} ...\", end=\" \", flush=True)\n",
    "    s3.download_file(AWS_BUCKET, key, dest_path)\n",
    "    print(\"✓\")\n",
    "\n",
    "print(\"✅ Download complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20ddf317-1a5b-4e28-8fba-1a67c7c4aa84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/Volumes/blockchain/ethereum/ethereum'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATALOG = dbutils.widgets.get(\"catalog_name\")\n",
    "SCHEMA = dbutils.widgets.get(\"schema_name\")\n",
    "NUM_FILES = int(dbutils.widgets.get(\"num_files\"))\n",
    "\n",
    "\n",
    "# Unity Catalog volume paths for data organization\n",
    "DATA_VOLUME = f\"/Volumes/{CATALOG}/{SCHEMA}/ethereum\"\n",
    "CHECKPOINT_VOLUME = f\"/Volumes/{CATALOG}/{SCHEMA}/ethereum_checkpoints\"\n",
    "SCHEMA_VOLUME = f\"/Volumes/{CATALOG}/{SCHEMA}/ethereum_schemas\"\n",
    "\n",
    "DATA_VOLUME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "348f121d-40ae-4e99-af60-99479ae665db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "reader = (\n",
    "    spark.readStream.format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\", \"parquet\")  \n",
    "        .option(\"cloudFiles.schemaLocation\", SCHEMA_VOLUME)  \n",
    "        .option(\"checkpointLocation\", CHECKPOINT_VOLUME)  # Required\n",
    "        .option(\"cloudFiles.schemaEvolutionMode\", \"addNewColumns\")  \n",
    "        .option(\"cloudFiles.schemaHints\", \"number BIGINT, baseFeePerGas BIGINT\")  \n",
    "        .load(f\"dbfs:{DATA_VOLUME}/blocks/\")\n",
    ")\n",
    "\n",
    "# Use append mode for non-aggregated streaming\n",
    "#display(reader, checkpointLocation=CHECKPOINT_VOLUME, outputMode=\"append\")\n",
    "\n",
    "# Extract and transform block-level fields if needed\n",
    "blocks_df = reader.select(\n",
    "   \"*\",\n",
    "   \"_metadata\"\n",
    ")\n",
    "\n",
    "# Write to Delta using Structured Streaming\n",
    "blocks_query = (\n",
    "    blocks_df.writeStream\n",
    "        .format(\"delta\")  # Delta Lake sink for ACID transactions\n",
    "        .outputMode(\"append\")  # Append new blocks as they arrive\n",
    "        .option(\"checkpointLocation\", f\"{CHECKPOINT_VOLUME}/blocks/\")  # State management\n",
    "        .trigger(availableNow=True)  # Process all available data\n",
    "        .table(f\"{CATALOG}.{SCHEMA}.blocks\")  # Save as managed Delta table\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c6973cc-c63d-4cdd-905c-4e0903daa350",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>COUNT(*)</th></tr></thead><tbody><tr><td>108555</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         108555
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "COUNT(*)",
            "nullable": false,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 81
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "COUNT(*)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- Total blocks ingested\n",
    "SELECT COUNT(*) \n",
    "FROM blockchain.ethereum.blocks;\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4323174122759272,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ethereum-block-parquet-download",
   "widgets": {
    "catalog_name": {
     "currentValue": "blockchain",
     "nuid": "7d368039-39b5-4ffe-b325-d482336941f5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "blockchain",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "blockchain",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "num_files": {
     "currentValue": "20",
     "nuid": "4b1f6133-a9cc-484a-a36a-d253ee9ce024",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "20",
      "label": "Number of Files to Download",
      "name": "num_files",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "20",
      "label": "Number of Files to Download",
      "name": "num_files",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema_name": {
     "currentValue": "ethereum",
     "nuid": "dd6dc6aa-c307-496e-86fc-f1d0765b3009",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ethereum",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ethereum",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}